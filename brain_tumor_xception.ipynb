{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -N -T -f firacode -tf loraserif -nf latosans -fs 100 -tfs 100 \\\n",
    "-nfs 100 -t monokai -cellw 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVGdTzozO9kp"
   },
   "source": [
    "# 458: A4 Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3nh3EmnO9kr"
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3056,
     "status": "ok",
     "timestamp": 1598829828172,
     "user": {
      "displayName": "Eric Chase",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQBnMo4EstGoIdt-4cW-TXKZh7Xop_tDQRQGfZ=s64",
      "userId": "15499799807361212443"
     },
     "user_tz": 420
    },
    "id": "tkvBnk5XO9ks",
    "outputId": "e5da9385-050b-4dda-c3bc-4bab0010fe27",
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tensorflow tools #\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.layers import (Dense, Input, MaxPooling2D, MaxPool2D, GlobalAveragePooling2D,\n",
    "                                     Conv2D, Flatten, Dropout, BatchNormalization) \n",
    "from tensorflow.keras.activations import sigmoid, softmax, relu\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, Adagrad, SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# ml viz\n",
    "from tensorboard.plugins.hparams import api as hp \n",
    "%load_ext tensorboard\n",
    "import pydot \n",
    "import graphviz \n",
    "# sklearn tools #\n",
    "import sklearn \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# image tools # \n",
    "from tensorflow.keras.preprocessing import image \n",
    "import cv2\n",
    "import imutils\n",
    "# data handling tools #\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "# plotting tools #\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "# general tools #\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import os \n",
    "pjoin = os.path.join\n",
    "import shutil\n",
    "import gc\n",
    "import pickle \n",
    "import itertools\n",
    "import re \n",
    "import string \n",
    "# import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21140,
     "status": "ok",
     "timestamp": 1598829846272,
     "user": {
      "displayName": "Eric Chase",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQBnMo4EstGoIdt-4cW-TXKZh7Xop_tDQRQGfZ=s64",
      "userId": "15499799807361212443"
     },
     "user_tz": 420
    },
    "id": "h8CpQhwKPNCp",
    "outputId": "bea2dfaa-c7a6-4fc3-8a5e-648af7619849"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !cp -rf ./drive/My\\ Drive/458_a4/train . \n",
    "    !cp -rf ./drive/My\\ Drive/458_a4/val . \n",
    "    !cp -rf ./drive/My\\ Drive/458_a4/test . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_y6tyc9O9kz"
   },
   "source": [
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OahAnWFIO9k0"
   },
   "outputs": [],
   "source": [
    "train_path, val_path, test_path = './train', './val', './test'\n",
    "if colab:\n",
    "    model_path = './drive/My Drive/458_a4/model'\n",
    "    bm_lists_path = './drive/My Drive/458_a4/bm_lists'\n",
    "    tb_log_path = './drive/My Drive/458_a4/tb_runlog'\n",
    "else:\n",
    "    model_path = './model'\n",
    "    bm_lists_path = './bm_lists'\n",
    "    tb_log_path = './tb_runlog'\n",
    "\n",
    "    \n",
    "path_ls = [train_path, val_path, test_path, model_path, bm_lists_path, tb_log_path]\n",
    "\n",
    "for path in path_ls:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BgilOMZqO9k3"
   },
   "source": [
    "# reproducibility & maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1W62axDO9k4"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(38)\n",
    "np.random.seed(38)\n",
    "_= gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMpFK5yPO9k6"
   },
   "source": [
    "# data view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1598830263937,
     "user": {
      "displayName": "Eric Chase",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQBnMo4EstGoIdt-4cW-TXKZh7Xop_tDQRQGfZ=s64",
      "userId": "15499799807361212443"
     },
     "user_tz": 420
    },
    "id": "0uiOl0HuO9k7",
    "outputId": "8551f797-e4c3-46e9-84f4-e1206fc916ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ./train/no_tumor:  262\n",
      "     ./train/meningioma_tumor:  262\n",
      "         ./train/glioma_tumor:  262\n",
      "      ./train/pituitary_tumor:  262\n",
      "               ./val/no_tumor:   65\n",
      "       ./val/meningioma_tumor:   65\n",
      "           ./val/glioma_tumor:   65\n",
      "        ./val/pituitary_tumor:   65\n",
      "              ./test/no_tumor:   81\n",
      "      ./test/meningioma_tumor:  113\n",
      "          ./test/glioma_tumor:   84\n",
      "       ./test/pituitary_tumor:   36\n"
     ]
    }
   ],
   "source": [
    "for maindir in [train_path, val_path, test_path]:\n",
    "    for subdir in os.listdir(maindir):\n",
    "        if os.path.isdir(os.path.join(maindir, subdir)):\n",
    "            n = len(os.listdir(os.path.join(maindir, subdir)))\n",
    "            print(f'{maindir}/{subdir}:'.rjust(30) + f'{n}'.rjust(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G5mWkq0O9k9"
   },
   "source": [
    "# data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tk51Mr8SO9k9"
   },
   "outputs": [],
   "source": [
    "# train generator instantiation \n",
    "train_im_datagen = image.ImageDataGenerator(\n",
    "                                      rescale=1./255, \n",
    "                                     rotation_range=.15, \n",
    "                                     width_shift_range=0, \n",
    "                                     height_shift_range=0, \n",
    "                                     brightness_range=(.1, .9),\n",
    "                                     shear_range=.15,\n",
    "                                     zoom_range=0,\n",
    "                                     horizontal_flip=True,\n",
    "                                     vertical_flip=True,\n",
    "                                     data_format='channels_last',\n",
    "                                     validation_split=0, \n",
    "                                    #  preprocessing_function=preprocess_input\n",
    "                                     )\n",
    "# test generator instantiation \n",
    "test_im_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    # preprocessing_function=preprocess_input\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvMjm_fnO9k_"
   },
   "outputs": [],
   "source": [
    "def get_data_gens(batch_size):\n",
    "    ''' Given the batch size, returns a tuple of generators from the \n",
    "        designated train, val, and test paths:  (traingen, valgen, testgen). '''\n",
    "    # train data flow inititalized #\n",
    "    traingen = train_im_datagen.flow_from_directory(train_path, \n",
    "                                                    target_size=target_size, \n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical', \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    shuffle=True,\n",
    "                                                    seed=38)\n",
    "    # val data flow inititalized #\n",
    "    valgen = test_im_datagen.flow_from_directory(val_path, \n",
    "                                                 target_size=target_size, \n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='categorical', \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 shuffle=False,\n",
    "                                                 seed=38)\n",
    "    # test data flow inititalized #\n",
    "    testgen = test_im_datagen.flow_from_directory(test_path, \n",
    "                                                  target_size=target_size, \n",
    "                                                  color_mode='rgb',\n",
    "                                                  class_mode='categorical', \n",
    "                                                  batch_size=batch_size, \n",
    "                                                  shuffle=False,\n",
    "                                                  seed=38)\n",
    "    \n",
    "    return traingen, valgen, testgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsvE6gjeO9lA"
   },
   "source": [
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quIMzWhuO9lB"
   },
   "outputs": [],
   "source": [
    "class Clock():\n",
    "    ''' A simple clock class that prints or hands back the elapsed time between \n",
    "        start and stop calls in a human friendly format. '''\n",
    "    import datetime\n",
    "    def __init__(self):\n",
    "        self.running = False\n",
    "        self.start_time = None\n",
    "        self.stop_time = None\n",
    "        self.elapsed = None\n",
    "        \n",
    "    def start(self):\n",
    "        self.running = True            \n",
    "        self.start_time = datetime.datetime.now()\n",
    "        \n",
    "    def stop(self, stdout=True, handback=False):\n",
    "        if self.running:\n",
    "            self.running = False\n",
    "            self.end_time = datetime.datetime.now()\n",
    "            self.delta = str(self.end_time - self.start_time).split(':')\n",
    "            self.delta[2] = self.delta[2][:2]\n",
    "#             self.elapsed = 'hours:{0[0]}, minutes:{0[1]}, seconds:{0[2]}'.format(self.delta)\n",
    "            self.elapsed = 'minutes:{0[1]}, seconds:{0[2]}'.format(self.delta)\n",
    "            if stdout:\n",
    "                print(self.elapsed)\n",
    "            if handback:\n",
    "                return self.elapsed\n",
    "            \n",
    "    def __repr__(self):\n",
    "        if self.running:\n",
    "            return 'The clock is running!'\n",
    "        else:\n",
    "            return 'The clock is not running.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSfYI5u8O9lC"
   },
   "outputs": [],
   "source": [
    "clock = Clock() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcOAkNXRO9lD"
   },
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6sWee4ZO9lD"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "_= gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBbV2W3bO9lF"
   },
   "source": [
    "## hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4oGv0-QzO9lF"
   },
   "outputs": [],
   "source": [
    "epochs = 2 \n",
    "target_size = (224,224)\n",
    "input_shape = (224,224,3)\n",
    "classes_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = [False]\n",
    "optimizer = ['adam', 'rmsprop']\n",
    "lr = [.00001, .001]\n",
    "momentum = [0., .5, .9]\n",
    "do_rate = [0., .2, .5]\n",
    "batch_normalize = [True, False]\n",
    "batch_size = [64, 128]\n",
    "dense_units = [128, 512, 1028]\n",
    "\n",
    "hyperparams = list(itertools.product(train_base, optimizer, lr, momentum, do_rate, \n",
    "                                     batch_normalize, batch_size, dense_units))\n",
    "param_names = \\\n",
    "'''train_base, optimizer, lr, momentum, do_rate, batch_normalize, batch_size, dense_units'''.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgxLZ5yXO9lP"
   },
   "source": [
    "## create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVZqoQK7O9lP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_model(name, hparams):\n",
    "    ''' Recieves a name for the model and the hyperparameters to create it and returns the \n",
    "        compiled model. '''\n",
    "    # optimizer #\n",
    "    if hparams['optimizer'] == 'adam':\n",
    "        optimizer = Adam(learning_rate=hparams['lr'])\n",
    "    elif hparams['optimizer'] == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=hparams['lr'], momentum=hparams['momentum'])\n",
    "\n",
    "    # conv base creation #\n",
    "    conv_base = keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg',\n",
    "    )\n",
    "    # conv base training adjustments #\n",
    "    if hparams['train_base']:\n",
    "        conv_base = True\n",
    "    else:\n",
    "        conv_base.trainable = False\n",
    "\n",
    "    # *******  input block  ******* #\n",
    "    input_ = Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # *******  conv base block  ******* #\n",
    "    x = conv_base(input_)\n",
    "    if hparams['batch_normalize'] == True:\n",
    "        x = BatchNormalization()(x)      \n",
    "    \n",
    "    # *******  dense block  ******* #\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hparams['dense_units'], 'relu')(x)\n",
    "    if hparams['batch_normalize'] == True:\n",
    "                x = BatchNormalization()(x)      \n",
    "    x = Dropout(hparams['do_rate'])(x)\n",
    "    \n",
    "    # output #\n",
    "    output_ = Dense(classes_dim, 'softmax', name='output')(x)\n",
    "    \n",
    "    \n",
    "    # *******  model  ******* #\n",
    "    m = Model(\n",
    "        inputs=[input_], \n",
    "        outputs=[output_], \n",
    "        name=name\n",
    "    )\n",
    "\n",
    "    # *******  compile  ******* #\n",
    "    m.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "\n",
    "    print(m.summary())\n",
    "    \n",
    "    return m\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_nEGdamO9lR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN0WDoIUO9lS"
   },
   "source": [
    "## train_test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q-AU8wzO9lS",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_test_model(m:tf.keras.Model, fname, hparams, epochs):\n",
    "    # cb for logging the metrics\n",
    "    tb_callback = keras.callbacks.TensorBoard(log_dir=fname, histogram_freq=1, \n",
    "                                              write_images=True)\n",
    "    # cb for logging the parameters\n",
    "    hp_callback = hp.KerasCallback(fname, hparams)\n",
    "    # cb for early stopping\n",
    "    earlystop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=.001, \n",
    "                                                       baseline=.25, patience=100)\n",
    "    # cb for reducing lr on plateau of val acc\n",
    "    red_lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=.2, \n",
    "                                                        min_delta=.001, patience=5, cooldown=0, \n",
    "                                                        min_lr=.000001)\n",
    "    # cb for saving model\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(pjoin(model_path, m.name), save_best_only=True)\n",
    "    \n",
    "    # data #\n",
    "    traingen, valgen, testgen = get_data_gens(hparams['batch_size'])\n",
    "    \n",
    "    # fit #\n",
    "    h = m.fit(traingen, \n",
    "              steps_per_epoch=(traingen.n // traingen.batch_size),\n",
    "              validation_data=valgen, \n",
    "              validation_steps=(valgen.n // valgen.batch_size),\n",
    "              epochs=epochs, \n",
    "              callbacks=[red_lr_callback, cp_callback, earlystop_callback])\n",
    "\n",
    "    # evaluate on test data #\n",
    "    test_loss, test_acc = m.evaluate(testgen)\n",
    "\n",
    "    return h.history, test_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCJE-OlTO9lT"
   },
   "source": [
    "## pickle_bm_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUmKoG_RO9lU"
   },
   "outputs": [],
   "source": [
    "def pickle_bm_lists(bm_ls_mapper, name):\n",
    "    for fname,ls in bm_ls_mapper.items():\n",
    "        with open(pjoin(bm_lists_path,  name + '_' + fname), 'wb') as file: \n",
    "            pickle.dump(ls, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvzNDbfFO9lV"
   },
   "source": [
    "## run_benchmarking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bng2pSDdO9lV"
   },
   "outputs": [],
   "source": [
    "def run_benchmarking():\n",
    "    ''' For the designated indices, the hyperparameter space is explored. All relevant benchmarks\n",
    "        are stored in lists and pickled in the current directory for safe keeping. '''\n",
    "    # maintenance #\n",
    "    keras.backend.clear_session() \n",
    "    gc.collect()\n",
    "    !rm -rf tb_log_path\n",
    "    # benchark lists #\n",
    "    history_ls, test_acc_ls, time_ls, param_ls = [], [], [], []\n",
    "    # benchmark lists fname mapper\n",
    "    bm_ls_mapper = {'history_ls.pkl':history_ls, 'test_acc_ls.pkl':test_acc_ls, \n",
    "                    'time_ls.pkl':time_ls, 'param_ls.pkl':param_ls}\n",
    "    # this is where distribution across multiple instances can be orchestrated #\n",
    "    start_idx, end_idx = 0, len(hyperparams)\n",
    "    \n",
    "    #******************************** run it ********************************#\n",
    "    for run in range(start_idx, end_idx):\n",
    "        params = hyperparams[run]\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "        print(f'\\n\\nRUN {run}\\n{param_dict}')\n",
    "\n",
    "        # maintenance #\n",
    "        keras.backend.clear_session() \n",
    "        gc.collect()\n",
    "        !rm -rf tb_log_path\n",
    "        # benchark lists #\n",
    "        history_ls, test_acc_ls, time_ls, param_ls = [], [], [], []\n",
    "        # benchmark lists fname mapper\n",
    "        bm_ls_mapper = {'history_ls.pkl':history_ls, 'test_acc_ls.pkl':test_acc_ls, \n",
    "                        'time_ls.pkl':time_ls, 'param_ls.pkl':param_ls}\n",
    "\n",
    "\n",
    "        #******************************** run it ********************************#\n",
    "        # create model #\n",
    "        m = create_model(f'frozen_{str(run)}', param_dict)\n",
    "\n",
    "        # train and test the model #\n",
    "        clock.start()\n",
    "        h, test_acc = train_test_model(m, \n",
    "                                        pjoin(tb_log_path, f'frozen_{str(run)}'),\n",
    "                                        param_dict,\n",
    "                                        epochs)\n",
    "        clock.stop() \n",
    "\n",
    "        # append current benchmarks to appropriate bm list\n",
    "        param_ls.append(param_dict)        \n",
    "        history_ls.append(h)\n",
    "        test_acc_ls.append(test_acc)\n",
    "        time_ls.append(clock.elapsed)\n",
    "\n",
    "        # save lists #\n",
    "        pickle_bm_lists(bm_ls_mapper, f'frozen_{str(run)}')\n",
    "\n",
    "    return 'finished' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zqn8cLSO9lW"
   },
   "source": [
    "## run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1713642,
     "status": "ok",
     "timestamp": 1598846012318,
     "user": {
      "displayName": "Eric Chase",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQBnMo4EstGoIdt-4cW-TXKZh7Xop_tDQRQGfZ=s64",
      "userId": "15499799807361212443"
     },
     "user_tz": 420
    },
    "id": "92CcpRzeO9lW",
    "outputId": "8c9cf892-ca2f-422a-f79b-2d4179c75589",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUN 0\n",
      "{'train_base': False, 'optimizer': 'adam', 'lr': 1e-05, 'momentum': 0.0, 'do_rate': 0.0, 'batch_normalize': True, 'batch_size': 64, 'dense_units': 128}\n",
      "Model: \"frozen_0\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 21,132,972\n",
      "Trainable params: 267,140\n",
      "Non-trainable params: 20,865,832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 1048 images belonging to 4 classes.\n",
      "Found 260 images belonging to 4 classes.\n",
      "Found 314 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8465 - accuracy: 0.2825WARNING:tensorflow:From /Users/ericchase/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/ericchase/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./model/frozen_0/assets\n",
      "16/16 [==============================] - 64s 4s/step - loss: 1.8465 - accuracy: 0.2825 - val_loss: 1.4015 - val_accuracy: 0.2500\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7336 - accuracy: 0.3018INFO:tensorflow:Assets written to: ./model/frozen_0/assets\n",
      "16/16 [==============================] - 73s 5s/step - loss: 1.7336 - accuracy: 0.3018 - val_loss: 1.3714 - val_accuracy: 0.2930\n",
      "5/5 [==============================] - 9s 2s/step - loss: 1.4228 - accuracy: 0.2930\n",
      "minutes:02, seconds:37\n",
      "\n",
      "\n",
      "RUN 1\n",
      "{'train_base': False, 'optimizer': 'adam', 'lr': 1e-05, 'momentum': 0.0, 'do_rate': 0.0, 'batch_normalize': True, 'batch_size': 64, 'dense_units': 512}\n",
      "Model: \"frozen_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 21,922,860\n",
      "Trainable params: 1,056,260\n",
      "Non-trainable params: 20,866,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 1048 images belonging to 4 classes.\n",
      "Found 260 images belonging to 4 classes.\n",
      "Found 314 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6104 - accuracy: 0.3535INFO:tensorflow:Assets written to: ./model/frozen_1/assets\n",
      "16/16 [==============================] - 77s 5s/step - loss: 1.6104 - accuracy: 0.3535 - val_loss: 1.3590 - val_accuracy: 0.3281\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3671 - accuracy: 0.4299INFO:tensorflow:Assets written to: ./model/frozen_1/assets\n",
      "16/16 [==============================] - 74s 5s/step - loss: 1.3671 - accuracy: 0.4299 - val_loss: 1.2951 - val_accuracy: 0.3711\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.3000 - accuracy: 0.4522\n",
      "minutes:02, seconds:52\n",
      "\n",
      "\n",
      "RUN 2\n",
      "{'train_base': False, 'optimizer': 'adam', 'lr': 1e-05, 'momentum': 0.0, 'do_rate': 0.0, 'batch_normalize': True, 'batch_size': 64, 'dense_units': 1028}\n",
      "Model: \"frozen_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1028)              2106372   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1028)              4112      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 4116      \n",
      "=================================================================\n",
      "Total params: 22,984,272\n",
      "Trainable params: 2,116,640\n",
      "Non-trainable params: 20,867,632\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 1048 images belonging to 4 classes.\n",
      "Found 260 images belonging to 4 classes.\n",
      "Found 314 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7491 - accuracy: 0.3130INFO:tensorflow:Assets written to: ./model/frozen_2/assets\n",
      "16/16 [==============================] - 76s 5s/step - loss: 1.7491 - accuracy: 0.3130 - val_loss: 1.3940 - val_accuracy: 0.2930\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4059 - accuracy: 0.4289INFO:tensorflow:Assets written to: ./model/frozen_2/assets\n",
      "16/16 [==============================] - 78s 5s/step - loss: 1.4059 - accuracy: 0.4289 - val_loss: 1.3186 - val_accuracy: 0.3711\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.3898 - accuracy: 0.3121\n",
      "minutes:02, seconds:54\n",
      "\n",
      "\n",
      "RUN 3\n",
      "{'train_base': False, 'optimizer': 'adam', 'lr': 1e-05, 'momentum': 0.0, 'do_rate': 0.0, 'batch_normalize': True, 'batch_size': 128, 'dense_units': 128}\n",
      "Model: \"frozen_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 21,132,972\n",
      "Trainable params: 267,140\n",
      "Non-trainable params: 20,865,832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 1048 images belonging to 4 classes.\n",
      "Found 260 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 314 images belonging to 4 classes.\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.0850 - accuracy: 0.2283"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-92337d78caa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### ******************* ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_benchmarking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m### ******************* ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-3dd493cdb213>\u001b[0m in \u001b[0;36mrun_benchmarking\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                                         \u001b[0mpjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb_log_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'frozen_{str(run)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                         \u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                         epochs)\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-7cc86a6433cc>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(m, fname, hparams, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mvalgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m               callbacks=[red_lr_callback, cp_callback, earlystop_callback])\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# evaluate on test data #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/assignments-LEBOTi4y/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runtime_clock = Clock()\n",
    "runtime_clock.start()\n",
    "\n",
    "### ******************* ###\n",
    "run_benchmarking()\n",
    "### ******************* ###\n",
    "\n",
    "runtime_clock.stop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK8H1R0BO9lX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmGIOC3BO9lY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEFtGtyZO9lY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-epuUKW0O9lZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4TN032RO9la"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-m1DQr2jO9lb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7CATIoOO9lc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LqHDcgGO9ld"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGgQkK3fO9ld"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mz3NbMDO9le"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHy05W0aO9lf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iwH7xUTO9lf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ewjmwmEO9lg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "a4_xceptionRMSprop1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
